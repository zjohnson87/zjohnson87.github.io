<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java on Zachary Johnson</title>
    <link>https://zjohnson87.github.io/tags/java/</link>
    <description>Recent content in Java on Zachary Johnson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://zjohnson87.github.io/tags/java/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Atlassian Deployment Triggers</title>
      <link>https://zjohnson87.github.io/projects/contributions/deploy-triggers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zjohnson87.github.io/projects/contributions/deploy-triggers/</guid>
      <description>Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.</description>
    </item>
    
    <item>
      <title>Checkers AI</title>
      <link>https://zjohnson87.github.io/projects/creations/checkers_ai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zjohnson87.github.io/projects/creations/checkers_ai/</guid>
      <description>An alpha-beta checkers-playing agent that takes the current game state and makes a legal move based on a heuristic function that evaluates candidate states.</description>
    </item>
    
    <item>
      <title>Stitch/Width Cut Image Processor</title>
      <link>https://zjohnson87.github.io/projects/creations/image-processor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zjohnson87.github.io/projects/creations/image-processor/</guid>
      <description>An image processing application created for COM S 311 (Analysis and Design of Algorithms). It can make width cuts to change the width of images while causing minimal distortion, and stitch cuts to combine two images together with minimal noticeability. Cuts are made based on calculated pixel importances. Pixels with high importance are less likely to be removed by the algorithm. The assignment was done as an academic demonstration of my ability to implement iterative dynamic programming algorithms.</description>
    </item>
    
    <item>
      <title>Web Crawler and Search Algorithm</title>
      <link>https://zjohnson87.github.io/projects/creations/web-crawler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zjohnson87.github.io/projects/creations/web-crawler/</guid>
      <description>A web crawler application created for COM S 311 (Analysis and Design of Algorithms). It uses breadth first search to generate a graph of web pages, starting from a seed URL and creating edges to all pages linked from that page (pages downloaded using jsoup). The graph generating method also has parameters &amp;quot;maxPages&amp;quot; and &amp;quot;maxDepth&amp;quot; to constrain the size of the graph. An inverted index containing the URLs, their content, and their indegrees is then created using the web graph.</description>
    </item>
    
  </channel>
</rss>
